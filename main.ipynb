{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VANGUARD AB TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METADATA HELP\n",
    "\n",
    "This comprehensive set of fields will guide your analysis, helping you unravel the intricacies of client behavior and preferences.\n",
    "\n",
    "- **client_id**: Every client’s unique ID.\n",
    "- **variation**: Indicates if a client was part of the experiment.\n",
    "- **visitor_id**: A unique ID for each client-device combination.\n",
    "- **visit_id**: A unique ID for each web visit/session.\n",
    "- **process_step**: Marks each step in the digital process.\n",
    "- **date_time**: Timestamp of each web activity.\n",
    "- **clnt_tenure_yr**: Represents how long the client has been with Vanguard, measured in years.\n",
    "- **clnt_tenure_mnth**: Further breaks down the client’s tenure with Vanguard in months.\n",
    "- **clnt_age**: Indicates the age of the client.\n",
    "- **gendr**: Specifies the client’s gender.\n",
    "- **num_accts**: Denotes the number of accounts the client holds with Vanguard.\n",
    "- **bal**: Gives the total balance spread across all accounts for a particular client.\n",
    "- **calls_6_mnth**: Records the number of times the client reached out over a call in the past six months.\n",
    "- **logons_6_mnth**: Reflects the frequency with which the client logged onto Vanguard’s platform over the last six months.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaning import *\n",
    "from mining import *\n",
    "from db_handling import *\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config.yaml\n",
    "config = parse_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary of all imported dataframes\n",
    "dataframes = { name:import_data_from_config(config, name) for name in config['tables']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: don't impose categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "dataframes = rename_columns(dataframes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "dataframes = select_columns(dataframes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataFrames(dataframes,'head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" variation_visits = visits_df.merge(experiment_df, on='client_id')\n",
    "display(variation_visits['variation'].value_counts())\n",
    "display(variation_visits)\n",
    "confirmed_steps = variation_visits[variation_visits['process_step'] == 'confirm']\n",
    "display(confirmed_steps)\n",
    "unique_visit_ids = confirmed_steps.drop_duplicates(subset='visit_id')\n",
    "display(unique_visit_ids) \"\"\"\n",
    "\"\"\" visits = variation_visits.groupby(['variation','process_step']).agg({'process_step':'count'})\n",
    "visits \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" display(unique_visit_ids['variation'].value_counts()) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = dataframes['clients']\n",
    "experiment_df = dataframes['experiment']\n",
    "visits_df = dataframes['visits']\n",
    "display(experiment_df['variation'].isna().sum())\n",
    "display (client_df, experiment_df, visits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the nulls from clients, but keep the list of the drops\n",
    "\n",
    "nulls_client_id = client_df[client_df.isna().any(axis=1)]['client_id']\n",
    "nulls_client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = client_df.dropna(axis=0)\n",
    "client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(client_df['gender'].value_counts(dropna = False))\n",
    "# x->u, keep 'U's for everything except the gender statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client_df['gender'] = client_df['gender'].replace(to_replace=r'.*X.*', value =\"U\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(experiment_df['variation'].value_counts(dropna = False))\n",
    "# keep NaN for general analysis of clients, but drop them from everywhere for test analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_df, experiment_df, visit_df -> for general analysis\n",
    "# new_client_df, new_experiment_df, new_visit_dfn -> for test/control analysis   experiment_df_null = \n",
    "nulls_in_experiment = experiment_df[experiment_df.isna().any(axis=1)]['client_id']\n",
    "nulls_in_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df removing client ID that are null in experiment\n",
    "\n",
    "new_experiment_df = experiment_df[~experiment_df['client_id'].isin(nulls_in_experiment)]\n",
    "display(new_experiment_df.count())\n",
    "\n",
    "new_experiment_df = new_experiment_df[~new_experiment_df['client_id'].isin(nulls_client_id)]\n",
    "display(new_experiment_df.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_visits_df = visits_df[~visits_df['client_id'].isin(nulls_in_experiment)]\n",
    "new_visits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_client_df = client_df[~client_df['client_id'].isin(nulls_in_experiment)]\n",
    "new_client_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['clients'] = new_client_df.copy()\n",
    "dataframes['experiment'] = new_experiment_df.copy()\n",
    "dataframes['visits'] = new_visits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Categorizing\n",
    "dataframes = clean_categorical_data(dataframes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert types\n",
    "dataframes = convert_types(dataframes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataFrames(dataframes, 'head', 'dtypes', 'cat_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = dataframes['clients']\n",
    "experiment_df = dataframes['experiment']\n",
    "visits_df = dataframes['visits']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['refresh_db']:\n",
    "\n",
    "    db_password = os.getenv('SQL_PASSWORD')\n",
    "\n",
    "    # Create database if it doesn't exist\n",
    "    engine = create_db(db_password, config)\n",
    "\n",
    "    # Export tables to database if refresh is set to true\n",
    "    export_dataframes_to_sql(engine, dataframes)\n",
    "\n",
    "    # Import data from database\n",
    "    dataframes = import_all_tables_from_sql(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Save files locally in an untracked folder\n",
    "export_dataframes_to_csv(dataframes) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO CAREFUL DATA WONT BE PROPERLY CATEGORIZED / TYPED run after : convert_types(dataframes, config)\n",
    "\"\"\" clients_df = pd.read_csv('data/cleaned/clients.csv')\n",
    "experiment_df = pd.read_csv('data/cleaned/experiment.csv')\n",
    "visits_df = pd.read_csv('data/cleaned/visits.csv') \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('clients :',client_df, 'experiment :',experiment_df, 'visits :',visits_df)\n",
    "\n",
    "experiment_df['variation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_since_year : redundant : drop\n",
    "# client_since_month: hypothesis : the longer they are client, the more valuable to us\n",
    "# client_since_month: hypothesis : the older the client is, the more valuable to us\n",
    "# gender: hypothesis : the men have more balance\n",
    "# number_of_accounts: hypothesis : the clients with more accounts have more balance\n",
    "# calls + logons : hypothesis : active clients are more valuable to us\n",
    "\n",
    "# process steps + time : \n",
    "    # - SUCCESS : All the steps, in order, in a reasonable amount of time for each step\n",
    "    \n",
    "    # - ERROR : path do not start with start : drop\n",
    "    # - ERROR : path do not complete : analyse\n",
    "    # - ERROR : path do not complete in order: analyse\n",
    "    # - ERROR : All the steps in order but took very long\n",
    "    # - ERROR : Unusual amount of time between steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added variation column to visits for easier analysis\n",
    "visits_variations = visits_df.merge(experiment_df, on='client_id', how='right')\n",
    "display(visits_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of visits per variation to calculate the success rate later\n",
    "number_of_visits = visits_variations.groupby('variation', observed=False)['visit_id'].nunique()\n",
    "display(number_of_visits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by visit_id and date_time to see the process steps in order\n",
    "visits_variations = visits_variations.sort_values(by=['visit_id', 'date_time'], ascending=[True, True])\n",
    "display(visits_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter visits with our happy path (thanks chatGPT)\n",
    "def filter_visits_with_happy_path(df):\n",
    "    def check_sequence(group):\n",
    "        steps = list(group['process_step'])\n",
    "        return steps == ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "\n",
    "    df_filtered = df.groupby('visit_id').filter(check_sequence)\n",
    "    return df_filtered\n",
    "\n",
    "happy_paths = filter_visits_with_happy_path(visits_variations)\n",
    "\n",
    "display(happy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the time difference between each step within the same visit_id in seconds\n",
    "happy_paths['time_taken'] = happy_paths.groupby('visit_id')['date_time'].diff().dt.total_seconds()\n",
    "happy_paths['time_taken'] = happy_paths['time_taken'].fillna(0)\n",
    "\n",
    "display(happy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to show the total time taken for each visit_id\n",
    "happy_paths['total_time_taken'] = happy_paths.groupby('visit_id')['time_taken'].transform('sum')\n",
    "display(happy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge client_df with happy paths to get demographic data\n",
    "happy_paths = happy_paths.merge(client_df, on='client_id', how='left')\n",
    "display(happy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average time taken for each step\n",
    "avg_time_taken = happy_paths.groupby('process_step', observed=False).agg({'time_taken':'mean'})\n",
    "display(avg_time_taken)\n",
    "\n",
    "# get the average total time taken \n",
    "avg_total_time_taken = happy_paths['total_time_taken'].mean()\n",
    "display(avg_total_time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the happy paths without the outliers for the total time taken (1.25 times the average) \n",
    "happy_paths_filtered = happy_paths[happy_paths['total_time_taken'] <= avg_total_time_taken * 1.25]\n",
    "display(happy_paths_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of success per variation\n",
    "number_of_successes = happy_paths_filtered.groupby('variation', observed=False)['visit_id'].nunique()\n",
    "display(number_of_successes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the success rate per variation\n",
    "success_rate = number_of_successes / number_of_visits\n",
    "display(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the happy paths confirmed steps\n",
    "confirmed_steps = happy_paths_filtered[happy_paths_filtered['process_step'] == 'confirm']\n",
    "\n",
    "# add numerical variation to the happy paths\n",
    "confirmed_steps.loc[:, 'variation_num'] = confirmed_steps['variation'].replace({'Control': 0, 'Test': 1}).astype(int)\n",
    "\n",
    "# add numerical gender to the happy paths\n",
    "confirmed_steps.loc[:, 'gender_num'] = confirmed_steps['gender'].replace({'M': 0, 'F': 1, 'U': 2}).astype(int)\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_data = confirmed_steps.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "display(correlation_matrix)\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROPORTION Z TEST ---- Proportion of successes is greater in Test group than in Control group\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "# H0: Proportion of complete steps in reasonable time in TEST group <= Proportion of complete steps in reasonable time in CONTROL group\n",
    "# H1: Pt > Pc\n",
    "alpha = 0.05\n",
    "successes = [number_of_successes['Test'], number_of_successes['Control']]\n",
    "just_visits = [number_of_visits['Test'], number_of_visits['Control']]\n",
    "proportions_ztest(successes, just_visits, alternative = \"larger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO SAMPLE T TEST ---- Average total_time of success is smaller in Test group than in Control group\n",
    "import scipy.stats as st\n",
    "# H0: average time it took to complete steps in test group is greater or equal to one in control group \n",
    "#       (Mean_time_test>=Mean_time_control)\n",
    "# H1: average time it took to complete steps is less in test group than in control group \n",
    "#       (Mean_time_test<Mean_time_control)\n",
    "alpha=0.05\n",
    "df_test = happy_paths_filtered[happy_paths_filtered['variation']=='Test']['total_time_taken']\n",
    "df_control = happy_paths_filtered[happy_paths_filtered['variation']=='Control']['total_time_taken']\n",
    "st.ttest_ind(df_test,df_control, equal_var=False, alternative = 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_time_per_variation = happy_paths_filtered.groupby('variation').agg({'total_time_taken': 'mean'})\n",
    "average_time_per_variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average total time without outliers\n",
    "avg_total_time = happy_paths_filtered['total_time_taken'].mean()\n",
    "display(avg_total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter out visits with start->confirm but no happy path in between them\n",
    "def filter_non_happy_path_visits(df):\n",
    "    def check_non_consecutive(group):\n",
    "        steps = list(group['process_step'])\n",
    "        if steps[0] == 'start' and steps[-1] == 'confirm':\n",
    "            if steps != ['start', 'step_1', 'step_2', 'step_3', 'confirm']:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    df_filtered = df.groupby('visit_id').filter(check_non_consecutive)\n",
    "    return df_filtered\n",
    "\n",
    "non_happy_paths = filter_non_happy_path_visits(visits_variations)\n",
    "\n",
    "display(non_happy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_visits = visits_variations.groupby('variation', observed=False)['visit_id'].nunique()\n",
    "display(number_of_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_visits_non_happy = non_happy_paths.groupby('variation', observed=False)['visit_id'].nunique()\n",
    "display(number_of_visits_non_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate_non_happy = number_of_visits_non_happy / number_of_visits\n",
    "display(success_rate_non_happy)\n",
    "# proportion of lost people is greater in test group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: consider binning / pd.cut / qcut for numerical data\n",
    "#TODO: correlation matrix\n",
    "#TODO: tukeys_test_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check back and forth between steps, lost?\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
