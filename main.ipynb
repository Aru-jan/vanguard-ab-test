{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VANGUARD AB TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METADATA HELP\n",
    "\n",
    "This comprehensive set of fields will guide your analysis, helping you unravel the intricacies of client behavior and preferences.\n",
    "\n",
    "- **client_id**: Every client’s unique ID.\n",
    "- **variation**: Indicates if a client was part of the experiment.\n",
    "- **visitor_id**: A unique ID for each client-device combination.\n",
    "- **visit_id**: A unique ID for each web visit/session.\n",
    "- **process_step**: Marks each step in the digital process.\n",
    "- **date_time**: Timestamp of each web activity.\n",
    "- **clnt_tenure_yr**: Represents how long the client has been with Vanguard, measured in years.\n",
    "- **clnt_tenure_mnth**: Further breaks down the client’s tenure with Vanguard in months.\n",
    "- **clnt_age**: Indicates the age of the client.\n",
    "- **gendr**: Specifies the client’s gender.\n",
    "- **num_accts**: Denotes the number of accounts the client holds with Vanguard.\n",
    "- **bal**: Gives the total balance spread across all accounts for a particular client.\n",
    "- **calls_6_mnth**: Records the number of times the client reached out over a call in the past six months.\n",
    "- **logons_6_mnth**: Reflects the frequency with which the client logged onto Vanguard’s platform over the last six months.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2784,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaning import *\n",
    "from mining import *\n",
    "from db_handling import *\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.proportion import proportions_ztest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config.yaml\n",
    "config = parse_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary of all imported dataframes\n",
    "dataframes = { name:import_data_from_config(config, name) for name in config['tables']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2788,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: don't impose categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2789,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "dataframes = rename_columns(dataframes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2790,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "dataframes = select_columns(dataframes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataFrames(dataframes,'head','shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = dataframes['clients']\n",
    "experiment_df = dataframes['experiment']\n",
    "visits_df = dataframes['visits']\n",
    "display (client_df, experiment_df, visits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the nulls from clients, but keep the list of the drops\n",
    "\n",
    "nulls_client_id = client_df[client_df.isna().any(axis=1)]['client_id']\n",
    "nulls_client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = client_df.dropna(axis=0)\n",
    "client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(experiment_df['variation'].value_counts(dropna = False))\n",
    "# keep NaN for general analysis of clients, but drop them from everywhere for test analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_df, experiment_df, visit_df -> for general analysis\n",
    "# new_client_df, new_experiment_df, new_visit_dfn -> for test/control analysis   experiment_df_null = \n",
    "nulls_in_experiment = experiment_df[experiment_df.isna().any(axis=1)]['client_id']\n",
    "nulls_in_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df removing client ID that are null in experiment\n",
    "\n",
    "display(experiment_df.count())\n",
    "new_experiment_df = experiment_df[~experiment_df['client_id'].isin(nulls_in_experiment)]\n",
    "display(new_experiment_df.count())\n",
    "\n",
    "new_experiment_df = new_experiment_df[~new_experiment_df['client_id'].isin(nulls_client_id)]\n",
    "display(new_experiment_df.count())\n",
    "display(new_experiment_df.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(visits_df)\n",
    "new_visits_df = visits_df[~visits_df['client_id'].isin(nulls_in_experiment)]\n",
    "display(new_visits_df)\n",
    "display(new_visits_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(client_df)\n",
    "new_client_df = client_df[~client_df['client_id'].isin(nulls_in_experiment)]\n",
    "display(new_client_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2800,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['clients'] = new_client_df.copy()\n",
    "dataframes['experiment'] = new_experiment_df.copy()\n",
    "dataframes['visits'] = new_visits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Categorizing\n",
    "dataframes = clean_categorical_data(dataframes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2802,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert types\n",
    "dataframes = convert_types(dataframes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataFrames(dataframes, 'head', 'shape', 'cat_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2804,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = dataframes['clients']\n",
    "experiment_df = dataframes['experiment']\n",
    "visits_df = dataframes['visits']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2805,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['refresh_db']:\n",
    "\n",
    "    db_password = os.getenv('SQL_PASSWORD')\n",
    "\n",
    "    # Create database if it doesn't exist\n",
    "    engine = create_db(db_password, config)\n",
    "\n",
    "    # Export tables to database if refresh is set to true\n",
    "    export_dataframes_to_sql(engine, dataframes)\n",
    "\n",
    "    # Import data from database\n",
    "    dataframes = import_all_tables_from_sql(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Save files locally in an untracked folder\n",
    "export_dataframes_to_csv(dataframes) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO CAREFUL DATA WONT BE PROPERLY CATEGORIZED / TYPED run after : convert_types(dataframes, config)\n",
    "\"\"\" clients_df = pd.read_csv('data/cleaned/clients.csv')\n",
    "experiment_df = pd.read_csv('data/cleaned/experiment.csv')\n",
    "visits_df = pd.read_csv('data/cleaned/visits.csv') \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('clients :',client_df, 'experiment :',experiment_df, 'visits :',visits_df)\n",
    "\n",
    "experiment_df['variation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added variation column to visits for easier analysis\n",
    "visits_variations = visits_df.merge(experiment_df, on='client_id', how='inner')\n",
    "display(visits_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge clients and visits for demographic analysis\n",
    "visits_variations = visits_variations.merge(client_df, on='client_id', how='inner')\n",
    "display(visits_variations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort visits by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by visit_id and date_time to see the process steps in order\n",
    "visits_variations = visits_variations.sort_values(by=['visit_id', 'date_time'], ascending=[True, True])\n",
    "display(visits_variations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_variations['time_taken'] = visits_variations.groupby('visit_id')['date_time'].diff().dt.total_seconds()\n",
    "visits_variations['time_taken'] = visits_variations['time_taken'].fillna(0)\n",
    "\n",
    "display(visits_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to show the total time taken for each visit_id\n",
    "visits_variations['total_time_taken'] = visits_variations.groupby('visit_id')['time_taken'].transform('sum')\n",
    "display(visits_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='variation', y='total_time_taken', data=visits_variations)\n",
    "plt.xlabel('Variation')\n",
    "plt.ylabel('Total Time Taken (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=visits_variations, x='total_time_taken', kde=True, bins=300)\n",
    "plt.xlabel('Total Time Taken (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2816,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tukeys_test_outliers(my_data, method=\"show\"):\n",
    "    data = my_data.copy()\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # Define bounds for the outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Identify the outliers\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    if method == \"show\":\n",
    "        return outliers\n",
    "    elif method == \"replace\":\n",
    "        median = data.median()\n",
    "        data.loc[outliers.index] = median\n",
    "        return data\n",
    "    elif method == \"delete\":\n",
    "        index_drop = outliers.index\n",
    "        data_no_outliers = data.drop(index_drop)\n",
    "        display(data_no_outliers)\n",
    "        return data_no_outliers.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations_outliers = tukeys_test_outliers(visits_variations['total_time_taken'], method=\"show\")\n",
    "display(variations_outliers)\n",
    "display(variations_outliers.describe())\n",
    "\n",
    "visits_variations = visits_variations[~visits_variations['total_time_taken'].isin(variations_outliers)]\n",
    "display(visits_variations)\n",
    "display(visits_variations.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=visits_variations, x='total_time_taken', kde=True, bins=50)\n",
    "plt.xlabel('Total Time Taken (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='variation', y='total_time_taken', data=visits_variations)\n",
    "plt.xlabel('Variation')\n",
    "plt.ylabel('Total Time Taken (seconds)')\n",
    "plt.show()\n",
    "\n",
    "visits_variations['total_time_taken'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of visits per variation to calculate the success rate later\n",
    "number_of_visits = visits_variations.groupby('variation', observed=False)['visit_id'].nunique()\n",
    "display(number_of_visits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Happy Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2821,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter visits with our happy path\n",
    "def filter_visits_with_happy_path(df):\n",
    "    def check_sequence(group):\n",
    "        steps = list(group['process_step'])\n",
    "        return steps == ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "\n",
    "    df_filtered = df.groupby('visit_id').filter(check_sequence)\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_paths = filter_visits_with_happy_path(visits_variations)\n",
    "\n",
    "display(happy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of success per variation\n",
    "number_of_successes = happy_paths.groupby('variation', observed=False)['visit_id'].nunique()\n",
    "display(number_of_successes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the success rate per variation\n",
    "success_rate = number_of_successes / number_of_visits\n",
    "display(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the happy paths confirmed steps\n",
    "confirmed_steps = happy_paths[happy_paths['process_step'] == 'confirm']\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_data = confirmed_steps.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "display(correlation_matrix)\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2826,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "successes = [number_of_successes['Test'], number_of_successes['Control']]\n",
    "trials = [number_of_visits['Test'], number_of_visits['Control']]\n",
    "\n",
    "# Perform two-proportion z-test\n",
    "stat, p_value = proportions_ztest(successes, trials)\n",
    "\n",
    "(stat, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROPORTION Z TEST ---- Proportion of successes is greater in Test group than in Control group\n",
    "# H0: Proportion of complete steps in reasonable time in TEST group <= Proportion of complete steps in reasonable time in CONTROL group\n",
    "# H1: Pt > Pc\n",
    "alpha = 0.05\n",
    "successes = [number_of_successes['Test'], number_of_successes['Control']]\n",
    "print(successes)\n",
    "just_visits = [number_of_visits['Test'], number_of_visits['Control']]\n",
    "print(just_visits)\n",
    "proportions_ztest(successes, just_visits, alternative = \"larger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO SAMPLE T TEST ---- Average total_time of success is smaller in Test group than in Control group\n",
    "import scipy.stats as st\n",
    "# H0: average time it took to complete steps in test group is greater or equal to one in control group \n",
    "#       (Mean_time_test>=Mean_time_control)\n",
    "# H1: average time it took to complete steps is less in test group than in control group \n",
    "#       (Mean_time_test<Mean_time_control)\n",
    "alpha=0.05\n",
    "df_test = happy_paths[happy_paths['variation']=='Test']['total_time_taken']\n",
    "df_control = happy_paths[happy_paths['variation']=='Control']['total_time_taken']\n",
    "st.ttest_ind(df_test,df_control, equal_var=False, alternative = 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_time_per_variation = happy_paths.groupby('variation').agg({'total_time_taken': 'mean'})\n",
    "average_time_per_variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average total time without outliers\n",
    "avg_total_time = happy_paths['total_time_taken'].mean()\n",
    "display(avg_total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter out visits with start->confirm but no happy path in between them\n",
    "def filter_non_happy_path_visits(df):\n",
    "    def check_non_consecutive(group):\n",
    "        steps = list(group['process_step'])\n",
    "        if steps[0] == 'start' and steps[-1] == 'confirm':\n",
    "            if steps != ['start', 'step_1', 'step_2', 'step_3', 'confirm']:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    df_filtered = df.groupby('visit_id').filter(check_non_consecutive)\n",
    "    return df_filtered\n",
    "\n",
    "non_happy_paths = filter_non_happy_path_visits(visits_variations)\n",
    "\n",
    "display(non_happy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_visits = visits_variations.groupby('variation', observed=False)['visit_id'].nunique()\n",
    "display(number_of_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_visits_non_happy = non_happy_paths.groupby('variation', observed=False)['visit_id'].nunique()\n",
    "display(number_of_visits_non_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate_non_happy = number_of_visits_non_happy / number_of_visits\n",
    "display(success_rate_non_happy)\n",
    "# proportion of lost people is greater in test group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2836,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: consider binning / pd.cut / qcut for numerical data\n",
    "#TODO: correlation matrix\n",
    "#TODO: tukeys_test_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check back and forth between steps, lost?\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAPPY PATH : START -> STEPS IN ORDER -> CONFIRM (in good time)\n",
    "### CONFUSED PATH : START -> STEPS IN WRONG ORDER -> CONFIRM (time?)\n",
    "### ERROR PATH : START -> ? -> NOT CONFIRM (time?)\n",
    "\n",
    "### DROPPED : 1 : ? -> ?\n",
    "### DROPPED : OUTLIERS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
